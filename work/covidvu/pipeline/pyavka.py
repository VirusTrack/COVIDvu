#!/usr/bin/env python3
# See: https://github.com/pr3d4t0r/COVIDvu/blob/master/LICENSE 
# vim: set fileencoding=utf-8:


from bs4 import BeautifulSoup

from covidvu.pipeline.vujson import SITE_DATA
from covidvu.pipeline.vudpatch import SCRAPED_US_DATA
from covidvu.pipeline.vudpatch import SCRAPED_WORLD_DATA

import csv
import os


# --- constants ---

US_TABLE_HTML    = os.path.join(SITE_DATA, 'table-01.html')
WORLD_TABLE_HTML = os.path.join(SITE_DATA, 'table-00.html')


# +++ functions +++

def _generateCSVTo(targetFileName, dataSource = WORLD_TABLE_HTML, ignoreRows = 6):
    """
    targetFileName ::= where to write the CSV
    dataSource     ::= the scraped HTML file generated by pyavka.sh
    ignoreRows     ::= heuristic for skipping the first row headers in the
                       dataSource.
    """
    rowCount = 0
    rows     = list()
    soup     = BeautifulSoup(open(dataSource).read(), 'html.parser')
    table    = soup.find('table')

    print('processing %s...' % dataSource)

    for tableRow in table.find_all('tr'):
        rowCount += 1

        if rowCount > ignoreRows:
            row     = list()
            for column in tableRow.find_all('td'):
                row.append(column.text.replace(',', '')) # number format comma
            
            if not len(row[0]):
                continue    # skip to next record
            
            rows.append(row[0:7])

    with open(targetFileName, 'w') as outputFile:
        csv.writer(outputFile, delimiter = '\t').writerows(rows)

    print('generated %s' % targetFileName)


def _main():
    _generateCSVTo(SCRAPED_WORLD_DATA, WORLD_TABLE_HTML, 6)
    _generateCSVTo(SCRAPED_US_DATA, US_TABLE_HTML, 5)


# --- main ---

if '__main__' == __name__:
    _main()

